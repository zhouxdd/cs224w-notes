I"hh<h2 id="measuring-networks-via-network-properties">Measuring Networks via Network Properties</h2>
<p>In this section, we study four key network properties to characterize a graph: <strong>degree distribution, path length, clustering coefficient</strong>, and <strong>connected components</strong>. Definitions will be presented for undirected graphs, but can be easily extended to directed graphs.</p>

<h3 id="degree-distribution">Degree Distribution</h3>
<p>The <strong>degree distribution</strong> <script type="math/tex">P(k)</script> measures the probability that a randomly chosen node has degree <script type="math/tex">k</script>. The degree distribution of a graph <script type="math/tex">G</script> can be summarized by a normalized histogram, where we normalize the histogram by the total number of nodes.</p>

<p>We can compute the degree distribution of a graph by <script type="math/tex">P(k) = N_k / N</script>. Here, <script type="math/tex">N_k</script> is the number of nodes with degree <script type="math/tex">k</script> and <script type="math/tex">N</script> is the number of nodes. One can think of degree distribution as the probability that a randomly chosen node has degree <script type="math/tex">k</script>.</p>

<p>To extend these definitions to a directed graph, compute separately both in-degree and out-degre distribution.</p>

<h3 id="paths-in-a-graph">Paths in a Graph</h3>
<p>A <strong>path</strong> is a sequence of nodes in which each node is linked to the next one:</p>

<script type="math/tex; mode=display">P_n = \{i_0, i_1, i_2, \dots, i_n\}</script>

<p>such that <script type="math/tex">\{(i_0, i_1), (i_1, i_2), (i_2, i_3), \dots, (i_{n-1}, i_n)\} \in E</script></p>

<p>The <strong>distance (shortest path, geodesic)</strong> between a pair of nodes is defined as the number of edges along the shortest path connecting the nodes. If two nodes are not connected, the distance is usually defined as infinite (or zero). One can also think of distance as the smallest number of nodes needed to traverse to get form one node to another.</p>

<p>In a directed graph, paths need to follow the direction of the arrows. Thus, distance is not symmetric for directed graphs. For a graph with weighted edges, the distance is the minimum number of edge weight needed to traverse to get from one node to another.</p>

<p>The <strong>average path length</strong> of a graph is the average shortest path between all connected nodes. We compute the average path length as</p>

<script type="math/tex; mode=display">\hat h = \frac{1}{2 E_{max}} \sum_{i, j \neq i} h_{ij}</script>

<p>where <script type="math/tex">E_{max}</script> is the max number of edges or node pairs; that is, <script type="math/tex">E_{max} = n (n-1) / 2</script> and <script type="math/tex">h_{ij}</script> is the distance from node <script type="math/tex">i</script> to node <script type="math/tex">j</script>. Note that we only compute the average path length over connected pairs of nodes, and thus ignore infinite length paths.</p>

<h3 id="clustering-coefficient">Clustering Coefficient</h3>
<p>The <strong>clustering coefficient</strong> (for undirected graphs) measures what proportion of node <script type="math/tex">i</script>’s neighbors are connected. For node <script type="math/tex">i</script> with degree <script type="math/tex">k_i</script>, we compute the clustering coefficient as</p>

<script type="math/tex; mode=display">C_i = \frac{2 e_i}{k_i (k_i - 1)}</script>

<p>where <script type="math/tex">e_i</script> is the number of edges between the neighbors of node <script type="math/tex">i</script>. Note that <script type="math/tex">C_i \in [0,1]</script>. Also, the clustering coefficient is undefined for nodes with degree 0 or 1.</p>

<p>We can also compute the <strong>average clustering coefficent</strong> as</p>

<script type="math/tex; mode=display">C = \frac{1}{N} \sum_{i}^N C_i.</script>

<p>The average clustering coefficient allows us to see if edges appear more densely in parts of the network. In social networks, the average clustering coefficient tends to be very high indicating that, as we expect, friends of friends tend to know each other.</p>

<h3 id="connectivity">Connectivity</h3>

<p>The <strong>connectivity</strong> of a graph measures the size of the largest connected component. The <strong>largest connected component</strong> is the largest set where any two vertices can be joined by a path.</p>

<p>To find connected components:</p>
<ol>
  <li>Start from a random node and perform breadth first search (BFS)</li>
  <li>Label the nodes that BFS visits</li>
  <li>If all the nodes are visited, the netowrk is connected</li>
  <li>Otherwise find an unvisited node and repeat BFS</li>
</ol>

<h2 id="the-erdös-rényi-random-graph-model">The Erdös-Rényi Random Graph Model</h2>

<p>The <strong>Erdös-Rényi Random Graph Model</strong> is the simplest model of graphs. This simple model has proven networks properties and is a good baseline to compare real-world graph properties with.</p>

<p>This random graph model comes in two variants:</p>
<ol>
  <li><strong><script type="math/tex">G_{np}</script></strong>: undirected graph on <script type="math/tex">n</script> nodes where each edge <script type="math/tex">(u,v)</script> appears IID with probability <script type="math/tex">p</script></li>
  <li><strong><script type="math/tex">G_{nm}</script></strong>: undirected graph with <script type="math/tex">n</script> nodes, and <script type="math/tex">m</script> edges picked uniformly at random</li>
</ol>

<p>Note that both the <script type="math/tex">G_{np}</script> and <script type="math/tex">G_{nm}</script> graph are not uniquely determined, but rather the result of a random procedure. Generating each graph multiple times results in different graphs.</p>

<h3 id="some-network-properties-of-g_np">Some Network Properties of <script type="math/tex">G_{np}</script></h3>

<p>The degree distribution of <script type="math/tex">G_{np}</script> is binomial. Let <script type="math/tex">P(k)</script> denotes the fraction of nodes with degree <script type="math/tex">k</script>, then</p>

<script type="math/tex; mode=display">P(k) = \binom{n-1}{k} p^k (1-p)^{n-1-k}</script>

<p>The mean and variance of a binomial distribution respectively are <script type="math/tex">\bar k = p(n-1)</script> and <script type="math/tex">\sigma^2 = p(1-p)(n-1)</script>. Below we include an image of binomial distributions for different paramters. Note that a binomial distribution is a discrete analogue of a Gaussian and has a bell-shape.</p>

<p><img src="../assets/img/binom_dist_graph.png?style=centerme" alt="binom-dist" /></p>

<p>One property of binomial distributions is that by the law of numbers, as the network size increases, the distribution becomes increasingly narrow. Thus, we are increasingly confidence that the degree of a ndoe is in the vicinity of <script type="math/tex">k</script>. If the graph has an infinite number of nodes, all nodes will have the same degree.</p>

<h3 id="the-clustering-coefficient-of-g_np">The Clustering Coefficient of <script type="math/tex">G_{np}</script></h3>
<p>Recall that the clustering coefficient is computed as <script type="math/tex">C_i = 2 \frac{e_i} {k_i (k_i -1)}</script> where <script type="math/tex">e_i</script> is the number of edges between <script type="math/tex">i</script>’s neighbors. Edges in <script type="math/tex">G_{np}</script> appear IID with probability <script type="math/tex">p</script>, so the expected <script type="math/tex">e_i</script> for <script type="math/tex">G_{np}</script> is</p>

<script type="math/tex; mode=display">\mathbb{E}[e_i] = p \frac{k_i(k_i - 1)}{2}</script>

<p>This is because <script type="math/tex">\frac{k_i(k_i - 1)}{2}</script> is the number of distinct pairs of neighbors of node <script type="math/tex">i</script> of degree <script type="math/tex">k_i</script>, and each pair is connected with probability <script type="math/tex">p</script>.</p>

<p>Thus, the expected clustering coefficient is</p>

<script type="math/tex; mode=display">\mathbb{E}[C_i] = \frac{p \cdot k_i (k_i - 1)}{k_i (k_i - 1)} = p = \frac{\bar k}{n-1} \approx \frac{\bar k}{n}.</script>

<p>where <script type="math/tex">\bar k</script> is the average degree. From this, we can see that the clustering coefficient of <script type="math/tex">G_{np}</script> is very small. If we generate bigger and bigger graphs with fixed average degree <script type="math/tex">\bar k</script>, then <script type="math/tex">C</script> decreases with graph size <script type="math/tex">n</script>. <script type="math/tex">\mathbb{E}[C_i] \to 0</script> as <script type="math/tex">n \to \infty</script>.</p>

<h3 id="the-path-length-of-g_np">The Path Length of <script type="math/tex">G_{np}</script></h3>
<p>To discuss the path length of <script type="math/tex">G_{np}</script>, we fist introduce the concept of <strong>expansion.</strong> Graph <script type="math/tex">G(V, E)</script> has expansion <script type="math/tex">\alpha</script> if <script type="math/tex">\forall S \subset V</script>, the number of edges leaving <script type="math/tex">S \geq \alpha \cdot \min (|S|, | V \setminus S|)</script>. Expansion answers the question ‘‘if we pick a random set of nodes, how many edges are going to leave the set?’’ Expansion is a measure of robustness: to disconnect <script type="math/tex">\ell</script> nodes, one must cut <script type="math/tex">\geq \alpha \cdot \ell</script> edges.</p>

<p>Equivalently, we can say a graph <script type="math/tex">G(V,E)</script> has an expansion <script type="math/tex">\alpha</script> such that</p>

<script type="math/tex; mode=display">\alpha = \min_{S \subset V} \frac{\# \text{ edges leaving $S$}}{\min(|S|, |V \setminus S|)}</script>

<p>An important fact about expansion is that in a graph with <script type="math/tex">n</script> nodes with expansion <script type="math/tex">\alpha</script>, for all pairs of nodes, there is a path of <script type="math/tex">O((\log n) / \alpha)</script> connecting them. For a random <script type="math/tex">G_{np}</script> graph, <script type="math/tex">\log n > np > c</script>, so <script type="math/tex">\text{diam}(G_{np}) = O(\log n / \log (np))</script>. Thus, we can see that random graphs have good expansion so it takes as logarithmic number of steps for BFS to visit all nodes.</p>

<p><img src="../assets/img/expansion.png?style=centerme" alt="expansion" /></p>

<p>Thus, the path length of <script type="math/tex">G_{np}</script> is <script type="math/tex">O(\log n)</script>. From this result, we can see that <script type="math/tex">G_{np}</script> can grow very large, but nodes will still remain a few hops apart.</p>

<p><img src="../assets/img/ER_path.png?style=centerme" alt="er-path" /></p>

<h3 id="the-connectivity-of-g_np">The Connectivity of <script type="math/tex">G_{np}</script></h3>
<p>The graphic below shows the evolution of a <script type="math/tex">G_{np}</script> random graph. We can see that there is an emergence of a giant component when average degree <script type="math/tex">\bar k = 2 E / n</script> or <script type="math/tex">p = \bar k / (n-1)</script>. If <script type="math/tex">k = 1 - \epsilon</script>, then all components are of size <script type="math/tex">\Omega(\log n)</script>. If <script type="math/tex">\bar k = 1 + \epsilon</script>, there exists 1 component of size <script type="math/tex">\Omega(n)</script>, and all other components have size <script type="math/tex">\Omega(\log n)</script>. In other words, if <script type="math/tex">\bar k > 1</script>, we expect a single large component. Additionally, in this case, each node has at least one edge in expectation.</p>

<p><img src="../assets/img/evol_of_rand_graph.png?style=centerme" alt="er-path" /></p>

<h3 id="analyzing-the-properties-of-g_np">Analyzing the Properties of <script type="math/tex">G_{np}</script></h3>

<p>In grid networks, we achieve triadic closures and high clustering, but long average path length.</p>

<p><img src="../assets/img/grid_network.png?style=centerme" alt="grid-network" /></p>

<p>In random networks, we achieve short average path length, but low clustering.</p>

<p><img src="../assets/img/random_network.png?style=centerme" alt="grid-network" /></p>

<p>Given the two above graph structures, it may seem unintuitive that graphs can have short average path length while also having high clustering. However, most real-world networks have such properties as in the below table, where <script type="math/tex">h</script> refers to the average shortest path length, <script type="math/tex">c</script> refers to the average clustering coefficient, and random graphs were generated with the same average degree as actual networks for comparison.</p>

<table>
  <thead>
    <tr>
      <th>Network</th>
      <th><script type="math/tex">h_{actual}</script></th>
      <th><script type="math/tex">h_{random}</script></th>
      <th><script type="math/tex">c_{actual}</script></th>
      <th><script type="math/tex">c_{random}</script></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Film actors</td>
      <td>3.65</td>
      <td>2.99</td>
      <td>0.79</td>
      <td>0.00027</td>
    </tr>
    <tr>
      <td>Power Grid</td>
      <td>18.70</td>
      <td>12.40</td>
      <td>0.080</td>
      <td>0.005</td>
    </tr>
    <tr>
      <td>C. elegans</td>
      <td>2.65</td>
      <td>2.25</td>
      <td>0.28</td>
      <td>0.05</td>
    </tr>
  </tbody>
</table>

<p>Networks that meet the above criteria of both high clustering and small average path length (mathematically defined as <script type="math/tex">L \propto \log N</script> where <script type="math/tex">L</script> is average path length and <script type="math/tex">N</script> is the total number of nodes in the network) are referred to as small world networks.</p>

<h2 id="the-small-world-random-graph-model">The Small World Random Graph Model</h2>

<p>In 1998, Duncan J. Watts and Steven Strogatz came up with a model for constructing a family of networks with both high clustering and short average path length. They termed this model the ‘‘small world model’’. To create such a model, we employ the following steps:</p>

<ol>
  <li>
    <p>Start with low-dimensional regular attic (ring) by connecting each node to <script type="math/tex">k</script> neighbors on its right and <script type="math/tex">k</script> neighbors on its left, with <script type="math/tex">k \geq 2</script>.</p>
  </li>
  <li>
    <p>Rewire each edge with probability <script type="math/tex">p</script> by moving its endpoint to a randomly chosen node.<label for="note-graphnetwork" class="margin-toggle sidenote-number"></label><input type="checkbox" id="note-graphnetwork" class="margin-toggle" /><span class="sidenote">Several variants of rewiring exist. To learn more, see <em>M. E. J. Newman. Networks, Second Edition, Oxford University Press, Oxford (2018)</em></span></p>
  </li>
</ol>

<p><img src="../assets/img/small_world.png?style=centerme" alt="Small World Model" /></p>

<p>Then, we make the following observations:</p>

<ul>
  <li>At <script type="math/tex">p = 0</script> where no rewiring has occured, this remains a grid network with high clustering, high diameter.</li>
  <li>For <script type="math/tex">% <![CDATA[
0 < p < 1 %]]></script> some edges have been rewired, but most of the structure remains. This implies both <strong>locality</strong> and <strong>shortcuts</strong>. This allows for both high clustering and low diameter.</li>
  <li>At <script type="math/tex">p = 1</script> where all edges have been randomly rewired, this is a Erdős–Rényi (ER) random graph with low clustering, low diameter.</li>
</ul>

<p><img src="../assets/img/clustering_path.png?style=centerme" alt="Clustering and Average Path Length" /></p>

<p>Small world models are parameterized by the probability of rewiring <script type="math/tex">p \in [0,1]</script>. By examining how the clustering coefficient and the average path length vary with values of <script type="math/tex">p</script>, we see that average path length falls off much faster as <script type="math/tex">p</script> increases, while the clustering coefficient remains relatively high. Rewiring introduces shortcuts, which allows for average path length to decrease even while the structure remains relatively strong (high clustering).</p>

<p>From a social network perspective, this phenomenon is intuitive. While most our friends are local, but we also have a few long distance friendships in different countries which is enough to collapse the diameter of the human social network, explaining the popular notion of “Six Degrees of Seperation”.</p>

<p>Two limitations of the Watts-Strogatz Small World Model are that its degree distribution does not match the power-law distributions of real world networks, and it cannot model network growth as the size of network is assumed.</p>

<h2 id="the-kronecker-random-graph-model">The Kronecker Random Graph Model</h2>

<p>Models of graph generation have been studied extensively. Such models allow us to generate graphs for simulations and hypothesis testing when collecting the real graph is difficult, and also forces us to examine the network properties that generative models should obey to be considered realistic.</p>

<p>In formulating graph generation models, there are two important considerations. First, the ability to generate realistic networks, and second, the mathematical tractability of the models, which allows for the rigorous analysis of network properties.</p>

<p>The Kronecker Graph Model is a recursive graph generation model that combines both mathematical tractability and realistic static and temporal network properties. The intuition underlying the Kronecker Graph Model is self-similarity, where the whole has the same shape as one or more of its parts.</p>

<p><img src="../assets/img/community_growth.png?style=centerme" alt="self-similarity" /></p>

<p>The Kronecker product, a non-standard matrix operation, is a way to generate self-similar matrices.</p>

<h3 id="the-kronecker-product">The Kronecker Product</h3>

<p>The Kronecker product is denoted by <script type="math/tex">\otimes</script>. For two arbitarily sized matrices <script type="math/tex">\textbf{A} \in \mathbb{R}^{m \times n}</script> and <script type="math/tex">\textbf{B} \in \mathbb{R}^{p \times q}</script>, <script type="math/tex">\textbf{A} \otimes \textbf{B} \in \mathbb{R}^{mp \times nq}</script> such that</p>

<script type="math/tex; mode=display">% <![CDATA[
\textbf{A} \otimes \textbf{B} = 
\begin{bmatrix} 
a_{11}\textbf{B}& \dots &a_{1n}\textbf{B}\\
\vdots &\ddots& \vdots\\
a_{m1}\textbf{B}& \dots & a_{mn}\textbf{B}
\end{bmatrix} %]]></script>

<p>For example, we have that</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{bmatrix} 1&2\\3&4 \end{bmatrix} \otimes \begin{bmatrix} 0&5\\6&7 \end{bmatrix} 
= \begin{bmatrix} 1  \begin{bmatrix} 0&5\\6&7 \end{bmatrix}  &2  \begin{bmatrix} 0&5\\6&7 \end{bmatrix}  \\3  \begin{bmatrix} 0&5\\6&7 \end{bmatrix}  &4  \begin{bmatrix} 0&5\\6&7 \end{bmatrix}  \end{bmatrix}
= \begin{bmatrix} 
1 \times 0 & 1 \times 5 & 2 \times 0 &  2 \times 5\\
1 \times 6 & 1 \times 7 & 2 \times 6 &  2 \times 7\\
3 \times 0 & 3 \times 5 & 4 \times 0 &  4 \times 5\\
3 \times 6 & 3 \times 7 & 4 \times 6 &  4 \times 7
\end{bmatrix}
= \begin{bmatrix} 
0 & 5 & 0 &  10\\
6 & 7 & 12 &  14\\
0 & 15 & 0 &  20\\
18 & 21 & 24 &  28
\end{bmatrix} %]]></script>

<p>To use the Kronecker product in graph generation, we define the Kronecker product of two graphs as the Kronecker product of the adjacency matrices of the two graphs.</p>

<p>Beginning with the initiator matrix <script type="math/tex">K_1</script> (an adjacency matrix of a graph), we iterate the Kronecker product to produce successively larger graphs, <script type="math/tex">K_2 = K_1 \otimes K_1, K_3 = K_2 \otimes K_1 \dots</script>, such that the Kronecker graph of order <script type="math/tex">m</script> is defined by</p>

<script type="math/tex; mode=display">K_1^{[m]}=\dots K_m = \underbrace{K_1 \otimes K_1 \otimes \dots K_1}_{\text{m times}}=  K_{m-1} \otimes K_1</script>

<p><img src="../assets/img/small_kronecker.png?style=centerme" alt="Kronecker" /></p>

<p>Intuitively, the Kronecker power construction can be imagined as recursive growth of the communities within the graph, with nodes in the community recursively getting expanded into miniature copies of the community.</p>

<p>The choice of the Kronecker initiator matrix <script type="math/tex">K_1</script> can be varied, which iteratively affects the structure of the larger graph.</p>

<p><img src="../assets/img/initiator.png?style=centerme" alt="Initiator" /></p>

<h3 id="stochastic-kronecker-graphs">Stochastic Kronecker Graphs</h3>

<p>Up to now, we have only considered <script type="math/tex">K_1</script> initiator matrices with binary values <script type="math/tex">\{0, 1\}</script>. However, such graphs generated from such initiator matrices have “staircase” effects in the degree distributions and other properties: individual values occur very frequently because of the discrete nature of <script type="math/tex">K_1</script>.</p>

<p>To negate this effect, stochasticity is introduced by relaxing the assumption that the entries in the initiator matrix can only take binary values. Instead entries in <script type="math/tex">\Theta_1</script> can take values on the interval <script type="math/tex">[0,1]</script>, and each represents the probability of that particular edge appearing. Then the matrix (and all the generated larger matrix products) represent the probability distribution over all possible graphs from that matrix.</p>

<p>More concretely, for probaility matrix <script type="math/tex">\Theta_1</script>, we compute the <script type="math/tex">k^{th}</script> Kronecker power <script type="math/tex">\Theta_k</script> as the large stochastic adjacency matrix. Each entry <script type="math/tex">p_{uv}</script> in <script type="math/tex">\Theta_k</script> then represents the probability of edge <script type="math/tex">(u,v)</script> appearing.</p>

<p><label for="note-bipartite-folded" class="margin-toggle">⊕</label><input type="checkbox" id="note-bipartite-folded" class="margin-toggle" /><span class="marginnote">Note that the probabilities do not have to sum up to 1 as each the probability of each edge appearing is independent from other edges.</span></p>

<p><img src="../assets/img/stochastic_graphs.png?style=centerme" alt="Stochastic" /></p>

<p>To obtain an instance of a graph, we then sample from the distribution by sampling each edge with probability given by the corresponding entry in the stochastic adjacency matrix. The sampling can be thought of as the outcomes of flipping biased coins where the bias is parameterized from each entry in the matrix.</p>

<p>However, this means that the time to naively generate an instance is quadratic in the size of the graph, <script type="math/tex">O(N^2)</script>; with 1 million nodes, we perform 1 million x 1 million coin flips.</p>

<h3 id="fast-generation-of-stochastic-kronecker-graphs">Fast Generation of Stochastic Kronecker Graphs</h3>

<p>A fast heuristic procedure that takes time linear in the number of edges to generate a graph exists.</p>

<p>The general idea can be described as follows: for each edge, we recurively choose sub-regions of the large stochastic matrix with probability proportional to <script type="math/tex">p_{uv} \in \Theta_1</script> until we descend to a single cell of the large stochastic matrix. We place the edge there. For a Kronecker graph of <script type="math/tex">k^{th}</script> power, <script type="math/tex">\Theta_k</script>, the descent will take <script type="math/tex">k</script> steps.</p>

<p>For example, we consider the case where <script type="math/tex">\Theta_1</script> is a <script type="math/tex">2 \times 2</script> matrix, such that</p>

<script type="math/tex; mode=display">% <![CDATA[
\Theta = \begin{bmatrix}
a & b \\
c & d
\end{bmatrix} %]]></script>

<p>For graph <script type="math/tex">G</script> with <script type="math/tex">n = 2^k</script> nodes:</p>
<ul>
  <li>Create normalized matrix <script type="math/tex">L_{uv} = \frac{p_{uv}}{\sum_{u,v} p_{uv}}, p_{uv} \in \Theta_1</script></li>
  <li>For each edge:
    <ul>
      <li>For <script type="math/tex">i = 1 \dots k</script>:
        <ul>
          <li>Start with <script type="math/tex">x = 0, y  = 0</script></li>
          <li>Pick the row, column <script type="math/tex">(u,v)</script> with probability <script type="math/tex">L_{uv}</script></li>
          <li>Descend into quadrant <script type="math/tex">(u,v)</script> based on step <script type="math/tex">i</script> of <script type="math/tex">G</script>
            <ul>
              <li>Set <script type="math/tex">x = x + u \cdot 2^{k-1}</script></li>
              <li>Set <script type="math/tex">y = y + v \cdot 2^{k-1}</script></li>
            </ul>
          </li>
          <li>Add edge <script type="math/tex">(x,y)</script> to <script type="math/tex">G</script></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>If <script type="math/tex">k=3</script>, and on each step <script type="math/tex">i</script>, we pick quadrants <script type="math/tex">b_{(0,1)}, c_{(1,0)}, d_{(1,1)}</script> respectively based on the normalized probabilities from <script type="math/tex">L</script>, then</p>

<p><script type="math/tex">x = 0 \cdot 2^{3-1} + 1 \cdot 2^{3-2} + 1 \cdot 2^{3-3} = 0 \cdot 2^2 + 1 \cdot 2^1 + 1 \cdot 2^0 = 3</script>
<script type="math/tex">y = 1 \cdot 2^{3-1} + 0 \cdot 2^{3-2} + 1 \cdot 2^{3-3} = 1 \cdot 2^2 + 0 \cdot 2^1 + 1 \cdot 2^0 = 5</script></p>

<p>Hence, we add edge <script type="math/tex">(3,5)</script> to the graph.</p>

<p>In practice, the stochastic Kronecker graph model is able to generate graphs that match the properties of real world networks well. To read more about the Kronecker Graph models, refer to <em>J Leskovec et al., Kronecker Graphs: An Approach to Modeling Networks (2010)</em>.<label for="note-graphnetwork" class="margin-toggle sidenote-number"></label><input type="checkbox" id="note-graphnetwork" class="margin-toggle" /><span class="sidenote">Estimating the initator matrice <script type="math/tex">\Theta_1</script> and fitting Kronecker Graphs to real world networks is also discussed in this work.</span></p>

<p><br /></p>

<table>
  <tbody>
    <tr>
      <td><a href="../">Index</a></td>
      <td><a href="./introduction-graph-structure">Previous</a></td>
      <td><a href="../">Next</a></td>
    </tr>
  </tbody>
</table>
:ET